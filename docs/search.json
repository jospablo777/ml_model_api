[
  {
    "objectID": "bikesharing_api.html#an-accesible-inference-system",
    "href": "bikesharing_api.html#an-accesible-inference-system",
    "title": "Bike Rentals Prediction API",
    "section": "An accesible inference system",
    "text": "An accesible inference system\nIn a fast-paced world, one of the problems we face as data professionals is delivering our data products promptly. Also, distributing them in a manner that doesn’t affect our productivity, for example, manually running a Jupyter Notebook or an R script every time someone needs insights, is awfully unproductive.\nAn idea that is not new, is to deliver the “answers” in an automated, from which the clients can self-serve each time they are in need. After we have a data product, for instance, a predictive model (machine learning if you are into buzzwords), we can make available its capabilities to our stakeholders via a micro service."
  },
  {
    "objectID": "bikesharing_api.html#an-ml-model-as-a-microservice",
    "href": "bikesharing_api.html#an-ml-model-as-a-microservice",
    "title": "Bike Rentals Prediction API",
    "section": "An ML model as a microservice",
    "text": "An ML model as a microservice\nImagine your (predictive) model being accessed anytime without disturbing your peace or consuming your time; after all, your time is expensive, and you have many tasks. Here is where the idea of microservices comes into action. A microservice is an isolated piece of software that is in charge of a single task (service) and communicates through a well-defined API. You finish your model, pack it in a microservice, and make it available through an API.\nThis way, the model will always be available, and its consumption won’t block other tasks. Also, more products could be potentially developed with the API."
  },
  {
    "objectID": "bikesharing_api.html#but-what-is-an-api",
    "href": "bikesharing_api.html#but-what-is-an-api",
    "title": "Bike Rentals Prediction API",
    "section": "But what is an API?",
    "text": "But what is an API?\nAn API is an intermediary that enables you to interact with a service without requiring knowledge of how this service works. You just need to know precisely what you want, tell it to the API, and the API will serve you what you requested.\nLet’s say that after work, you get hungry, so you park your Capital Bikeshare™ bike out of your favorite Mexican restaurant1. You enter the restaurant and sit at a table. Instead of going directly to the kitchen to cook your own meal or asking the chef what you want, you need to place your order through the waiter or waitress. You kindly request your enchiladas, and after a while, they bring your meal to you.\n\n\n\nAllegory of a restaurant. The waiter/waitress is the API; the kitchen is the service (they are dedicated to cooking); you are the client\n\n\nNotice that you, as the client, are not required to know how to cook enchiladas. Also, you do not interact directly with the people who prepare the food. You get what you want through a waiter (the API).\nIn summary, an API is the piece of the system you interact with to get a result generated by a service. Producing this result might be complex, but you don’t care about that since you only have to deal with the API."
  },
  {
    "objectID": "bikesharing_api.html#software-engineering-for-data-scientists",
    "href": "bikesharing_api.html#software-engineering-for-data-scientists",
    "title": "Bike Rentals Prediction API",
    "section": "Software engineering for data scientists",
    "text": "Software engineering for data scientists\nAnother problem common to data scientists is that research, predictive modeling, and analytics are dirty processes. This is partly due to a lack of training in software engineering, which involves design, testing, and software maintenance.\nWe usually have many problems to solve, questions to answer, and limited time at work. This leaves little to no time to apply the best practices to develop our analysis and maintain our code, leaving a trail of technical debt with each delivery. Yet, since most of us write code, we are, in fact, software developers because we develop software. This should be a hard-to-miss hint that software engineering practices must be core in our profession, or at least not ignored.\nHere, we will implement some practices core of software engineering like:\n\nCI/CD: Continuous Integration (CI) and Continuous Deployment (CD) with GitHub Actions.\nAutomated tests: unit, integration, and inference tests with pytest.\nContainerization: package the application with Docker for consistency across environments (i.e., it should work on every machine with a well-setup Docker). Dependency Management: For reproducibility, dependencies were specified in a requirements.txt file, and development was conducted in an isolated environment (venv).\nMicroservices architecture: The project is a self-contained microservice focused on a single responsibility: predicting bike rentals. It is independently deployable and communicates through HTTP.\n\nWe intend to review these concepts in a practical, applied way. This will give us more tools to design and produce more sustainable systems, which we can develop more efficiently through good practices without sacrificing smooth delivery to our clients."
  },
  {
    "objectID": "bikesharing_api.html#about-the-technologies",
    "href": "bikesharing_api.html#about-the-technologies",
    "title": "Bike Rentals Prediction API",
    "section": "About the technologies",
    "text": "About the technologies\nThrough this practical project, we will deal with several technologies, the most important:\n\nFastAPI: a framework to develop APIs with Python. It is easy to learn, and it makes the development of APIs incredibly fast.\nUvicorn: an ASGI (Asynchronous Server Getaway Interface) Server. It handles incoming HTTP requests and sends responses. This lightweight server is appropriate for our microservice.\nDocker: a platform to pack our application into isolated “containers” and make them available to be run in several systems. Perfect to build microservices.\nGitHub Actions: a CI/CD platform that allows us to automate your development pipelines. We will use them here to automate the software tests and build and push our docker images.\npytest: a Python framework to simplify our software testing.\n\nThese tools will make the development and publishing of our microservice a breeze."
  },
  {
    "objectID": "bikesharing_api.html#lets-get-started",
    "href": "bikesharing_api.html#lets-get-started",
    "title": "Bike Rentals Prediction API",
    "section": "Let’s get started",
    "text": "Let’s get started\nWe will start with the mandatory xkcd comic that this kind of articles include so we can continue with the tutorial.\n\n\n\nExploits of a Mom, by xkcd Comics. Available at https://xkcd.com/3027/\n\n\nI know that this has nothing to do with software engineering or APIs, but little Bobby Tables always cracks me laugh. Now we can continue with the build of our API and some software engineering practices."
  },
  {
    "objectID": "bikesharing_api.html#problem-we-want-to-solve",
    "href": "bikesharing_api.html#problem-we-want-to-solve",
    "title": "Bike Rentals Prediction API",
    "section": "Problem we want to solve",
    "text": "Problem we want to solve\nNow, let’s focus on the problem we want to solve; this is probably the most crucial step since it is how we add value to the business. We are hired to solve analytical problems with evidence (data) as our raw material to produce those solutions.\nYou probably won’t be surprised to learn this project started as a Jupyter Notebook, which I encourage you to check out here. We are using an open data set from the UCI Machine Learning Repository.\nLet’s assume we are working for Capital Bikeshare, a company dedicated to providing a self-service bike rental service managed through a mobile app. For the company, it is crucial to predict the peaks of service usage so they can restock or make more available their products when they’re more needed. These products can be cloud computing resources during peak hours, bicycle units, human staff, etc. Also it can b convenient to predict the dates and hours of least use for maintenance tasks, like server updates or bike maintenance.\n\n\n\nCapital Bikeshare station outside of the Eastern Market Metro station. Author: Ben Schumin (2010). Licensed under CC BY-SA 3.0\n\n\nWorking as a data scientist for a big tech transport company, you will have lots of data and computational resources. On this occasion, you were put in charge of finding a way to predict the days and hours they will have to replenish their stock and increase the server’s capacity, investing in more resources only when necessary (saving money). Also, knowing when to schedule the maintenance labor will be valuable as well.\nAfter finishing the data exploration, you know that working days and the entry and exit from work hours are the busiest time frames. Also, climatic conditions can affect the willingness to rent a bike. You are cautious, so you first took the time to understand the phenomenon. Then, you built the model prototype and corroborated that it is possible to forecast the number of rented bikes at an hour-of-the-day granularity level.\nSuccess! You have a model that can help determine the best time to provide more resources or the times for maintenance. Does this mean that you have already finished with the task and can go on to live the good life?2 Well, you already know that Jupyter is not a tool that produces clean results and that if you leave it there, your model will have to be run manually each time, which can introduce bugs and errors. This also means that you will have a high and constant influx of people knocking at your door3 asking for predictions and insights.\nJupyter is ideal for experimenting and testing but not for delivering results. Hence, you have decided to deploy this first iteration of the model (the prototype) as a microservice that can be consumed via an API. Here, you can assess how the model behaves in the wild and prepare for future iterations. You will start adding value with predictions and valuable information that will help improve your model.\nThe engineering team, for example, will quickly adopt the app to know when to conduct maintenance jobs."
  },
  {
    "objectID": "bikesharing_api.html#microservice-development",
    "href": "bikesharing_api.html#microservice-development",
    "title": "Bike Rentals Prediction API",
    "section": "Microservice development",
    "text": "Microservice development\nWe were assigned a task, so we started by investigating bike rental data and then continued by building a predictive model using the CatBoost algorithm. This model will be the inference engine of our microservice. You can see this part of the project here in the notebook4. We saved the model in our project’s predictive_models/ folder.\n\n\n\n\n\n\nNote\n\n\n\nDuring this tutorial, we will show you some code snippets and indicate the file where the code is located5. You should then be able to follow the project’s code, which is available on the GitHub repo.\n\n\nAfter some research and experimentation, we developed a CatBoost model capable of predicting the number of rented bikes at a specific time, given some environmental and temporal conditions. The code that generated the model is next.\nFilename: notebooks/eda_and_toy_model.ipynb\n\nfrom catboost import CatBoostRegressor\n\n# --snip--\n\n# Instantiate our model\ncatboost_model = CatBoostRegressor(\n    iterations=1000,       # Boosting iterations\n    learning_rate=0.1,\n    depth=6,               # Tree depth\n    loss_function='RMSE',  # Loss\n    verbose=100            # Let it print the learning state every 100 iterations\n)\n\n# Train\ncatboost_model.fit(X_train, y_train, cat_features=categorical_features)\n\n# --snip--\n\n# Save trained model\ncatboost_model.save_model(\"../predictive_models/catboost_model_19Dec2024.cbm\")\n\nIn this analysis, we generated some insights6 and the core of our microservice, a predictive model stored in predictive_models/catboost_model_19Dec2024.cbm. Now that we have our predictor, let’s see how we can make the predictions accessible to others in the company."
  },
  {
    "objectID": "bikesharing_api.html#api-development",
    "href": "bikesharing_api.html#api-development",
    "title": "Bike Rentals Prediction API",
    "section": "API development",
    "text": "API development\nThe API will move data around (receive and deliver) as its primary job, so it is key to establish a clear set of rules for the data our clients send. Moving back to our restaurant example, you probably could put your enchiladas order in English or Spanish, but it might be hard for the waiter if you place the order in Japanese7. Hence, to get your enchiladas, you must request them in a way that the staff can understand, and Pydantic is here to enforce the rules that make such understanding happen.\n\n\n\nAn ambiguous (and invalid) request request to the API, so no enchiladas :(\n\n\n\nThe Pydantic model\nWe will start this section by defining our Pydantic model. Pydantic is a library for data validation that uses Python-type annotations. Let’s establish a Pydantic model for our API requests and learn more about the library in the process.\nFilename: app/models/bike_sharing.py\n\nfrom pydantic import BaseModel, Field, field_validator\n\n1class BikeSharingRequest(BaseModel):\n2    season: str = Field(..., description=\"Season (Winter/Spring/Summer/Fall)\")\n    mnth: str = Field(..., description=\"Month name (January, etc.)\")\n3    hr: int = Field(..., ge=0, le=23, description=\"Hour of the day\")\n    holiday: str = Field(..., description=\"Yes/No if holiday\")\n    weekday: str = Field(..., description=\"Name of the weekday (Monday/Tuesday/Wednesday/Thursday/Friday/Saturday/Sunday)\")\n4    workingday: str = Field(..., description=\"Yes/No if working day\")\n    weathersit: int = Field(..., description=\"Weather code\")\n    temp: float = Field(..., ge=0, le=1, description=\"Normalized temperature\")\n    atemp: float = Field(..., ge=0, le=1, description=\"Normalized feeling temperature\")\n    hum: float = Field(..., ge=0, le=1, description=\"Normalized humidity\")\n    windspeed: float = Field(..., ge=0, le=1, description=\"Normalized wind speed\")\n\n5    @field_validator(\"season\")\n6    def validate_season(cls, v):\n        allowed = {\"Winter\", \"Spring\", \"Summer\", \"Fall\"} \n7        if v not in allowed:\n8            raise ValueError(f\"season must be one of {allowed}\")\n        return v\n\n# -- snip -- (validators continue)\n\n\n1\n\nThe first thing to notice is that the Pydantic model is defined as a Python class that inherits from BaseModel; this is the Pydantic base class used to create models with built-in data validation.\n\n2\n\nEach class attribute is defined with a data type; season, for example, is defined as str. We also use the function Field() to specify constraints and metadata; the ellipsis literal ... here means two things: first, a value must be provided, and second, there is no default value for this attribute. Then, some metadata is specified in the description parameter.\n\n3\n\nFor hr attribute, we have constraints used for numeric validation. So, ge=0 means that the hour has to be greater or equal to 0, while le=23 indicates that the hour should be less or equal to 23. So if the user send a request with hr=-1 the system will complain and throw a warning.\n\n4\n\nWith what we know so far, we could read this line as “workingday is a required str field with a description.”\n\n5\n\nWe have the field_validator decorator8 to build custom validation logic for a specific field. Besides the already fantastic default capabilities of Pydantic, we can define our custom validations. In this case, we want to be sure that the client will provide only valid values for the season field. CatBoost uses categories as predictors, and it is case sensitive (i.e., \"Summer\" != \"summer). With this extra step, FastAPI will send a custom message to the client, informing that the API expects \"Summer\" not \"summer\".\n\n6\n\nWe define the function validate_season, which takes two parameters: cls, a keyword indicating a reference to the class (BikeSharingRequest), and v, representing the value of the field we’re validating.\n\n7\n\nCheck if the value we validate is within the allowed set.\n\n8\n\nRaise an error if the value is not allowed; it also tells the client which values are expected.\n\n\n\n\nTo summarize the structure of our Pydantic model:\n\n1from pydantic import BaseModel, Field, field_validator\n\n2class BikeSharingRequest(BaseModel):\n3    season: str = Field(..., description=\"Season (Winter/Spring/Summer/Fall)\")\n    mnth: str = Field(..., description=\"Month name (January, etc.)\")\n    hr: int = Field(..., ge=0, le=23, description=\"Hour of the day\")\n    holiday: str = Field(..., description=\"Yes/No if holiday\")\n    weekday: str = Field(..., description=\"Name of the weekday (Monday/Tuesday/Wednesday/Thursday/Friday/Saturday/Sunday)\")\n    workingday: str = Field(..., description=\"Yes/No if working day\")\n    weathersit: int = Field(..., description=\"Weather code\")\n    temp: float = Field(..., ge=0, le=1, description=\"Normalized temperature\")\n    atemp: float = Field(..., ge=0, le=1, description=\"Normalized feeling temperature\")\n    hum: float = Field(..., ge=0, le=1, description=\"Normalized humidity\")\n    windspeed: float = Field(..., ge=0, le=1, description=\"Normalized wind speed\")\n\n4    @field_validator(\"season\")\n    def validate_season(cls, v):\n        allowed = {\"Winter\", \"Spring\", \"Summer\", \"Fall\"}\n        if v not in allowed:\n            raise ValueError(f\"season must be one of {allowed}\")\n        return v\n\n# -- snip -- (validators continue)\n\n\n1\n\nRequired Pydantic imports.\n\n2\n\nThe model is defined as a Python class.\n\n3\n\nWithin the class, we define the model’s fields as attributes of the class\n\n4\n\nWe can include custom validators within the model.\n\n\n\n\nGreat! Now, we have a Pydantic model and a better understanding of it. Next, we will work on our API.\n\n\nFastAPI development\nWith the data model in place (the class BikeSharingRequest), we can continue developing our microservice served via an API."
  },
  {
    "objectID": "bikesharing_api.html#automated-tests",
    "href": "bikesharing_api.html#automated-tests",
    "title": "Bike Rentals Prediction API",
    "section": "Automated tests",
    "text": "Automated tests"
  },
  {
    "objectID": "bikesharing_api.html#containarization",
    "href": "bikesharing_api.html#containarization",
    "title": "Bike Rentals Prediction API",
    "section": "Containarization",
    "text": "Containarization"
  },
  {
    "objectID": "bikesharing_api.html#inference",
    "href": "bikesharing_api.html#inference",
    "title": "Bike Rentals Prediction API",
    "section": "Inference",
    "text": "Inference"
  },
  {
    "objectID": "bikesharing_api.html#microservice-up-and-running",
    "href": "bikesharing_api.html#microservice-up-and-running",
    "title": "Bike Rentals Prediction API",
    "section": "Microservice up and running",
    "text": "Microservice up and running"
  },
  {
    "objectID": "bikesharing_api.html#what-we-learned",
    "href": "bikesharing_api.html#what-we-learned",
    "title": "Bike Rentals Prediction API",
    "section": "What we learned?",
    "text": "What we learned?"
  },
  {
    "objectID": "bikesharing_api.html#whats-left",
    "href": "bikesharing_api.html#whats-left",
    "title": "Bike Rentals Prediction API",
    "section": "Whats left?",
    "text": "Whats left?\nModel monitoring, automatic training incorporated to the CI/CD, model versioning, high level applications that consume the APIs"
  },
  {
    "objectID": "bikesharing_api.html#recommended-readings",
    "href": "bikesharing_api.html#recommended-readings",
    "title": "Bike Rentals Prediction API",
    "section": "Recommended readings",
    "text": "Recommended readings\n\nMicroservice APIs by Jose Haro Peralta\nIf you’re new to APIs and microservices, Microservice APIs by Jose Haro Peralta provides an excellent starting point. The author presents fundamental software architecture and engineering principles in an accessible, hands-on way. You’ll find practical code examples to experiment with, paired with clear theoretical explanations that help you understand both the “how” and the “why” behind the code.\n\n\nDocker Deep Dive by Nigel Poulton\nFor anyone looking to learn Docker, Nigel Poulton’s Docker Deep Dive offers a concise yet insightful introduction. Despite its brevity, the book covers many concepts and provides straightforward exercises. By following along with the examples, you’ll quickly gain the confidence to use Docker effectively in real-world scenarios.\n\n\nSoftware Engineering for Data Scientists by Andrew Treadway\nCurrently available as a MEAP (Manning Early Access Program), Software Engineering for Data Scientists by Andrew Treadway is a remarkable resource for data professionals eager to strengthen their software engineering skills. The book’s in-progress chapters seamlessly blend theory and practice, offering well-researched explanations and practical examples. This is a must-read if you want to elevate your data projects with solid engineering principles."
  },
  {
    "objectID": "bikesharing_api.html#about-the-pondering-guy-in-the-header",
    "href": "bikesharing_api.html#about-the-pondering-guy-in-the-header",
    "title": "Bike Rentals Prediction API",
    "section": "About the pondering guy in the header",
    "text": "About the pondering guy in the header\nIt’s the wizard from “Pondering My Orb.” The art is the work by Angus Mcbride and was featured in a Lord of the Rings game book :) you can check Know Your Meme for more info/memes."
  },
  {
    "objectID": "bikesharing_api.html#footnotes",
    "href": "bikesharing_api.html#footnotes",
    "title": "Bike Rentals Prediction API",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis must be how George R. R. Martin feels when foreshadowing a major (traumatic) event in his novels.↩︎\nAt the time of writing, I am aware that “no” is the answer since we’re still just at the introduction of this tutorial.↩︎\nIt’s even worse today, in our modern remote era. The dreaded Microsoft Teams ringtone will constantly haunt you.↩︎\nYou probably already noticed that we keep bringing up the link to this notebook. That’s because we spent so much time on it, and we was hoping you could look at our precious.↩︎\nI learned this tip for technical writing from “The Rust Programming Language” book by Steve Klabnik, Carol Nichols, and the Rust Community. The book is a masterpiece and a highly recommended reading; you can find it here.↩︎\nWhoops, here is the notebook again. When presenting results to my stakeholders as a habit, I always prepare two decks, one with very high-level results and a second highly technical one with all the math of the statistical/ML models and intricacies of the system design, just in case somebody has a question on the interesting technical part. This is expecting a deep, nerdy discussion about models, gaps, opportunities, and science; to date, the counts for the times I’ve used this second deck remain at 0. The good news is that it might be a proxy of our stakeholders’ trust in us.↩︎\nエンチラーダをいただけますか？↩︎\nA decorator is a function whose intention is to modify the behavior of other functions; it takes the original function and converts it into a different function. Luciano Ramalho does a great job explaining decorators in chapter 9 of his book “Fluent Python”.↩︎"
  }
]